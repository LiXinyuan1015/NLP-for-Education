# Survey-of-Natural-Language-Processing-for-Education-Taxonomy-Systematic-Review-and-Future-Trends

This is a list of papers and dataset URLs cited by our paper "Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends".

## Contents

- [Papers](#Papers)

  - [Introduction & Taxonomy](#Introduction-&-Taxonomy)
  - [Question Answering](#Question-Answering)
    * [Textbook Question Answering](#Textbook-Question-Answering)
    * [Math Word Problem Solving](#Math-Word-Problem-Solving)
  - [Question Construction](#Question-Construction)
    * [Question Generation](#Question-Generation)
    * [Distractor Generation](#Distractor-Generation)
  - [Automated Assessment](#Automated-Assessment)
    * [Automated Essay Scoring](#Automated-Essay-Scoring)
    * [Automated Code Scoring](#Automated-Code-Scoring)
  - [Error Correction](#Error-Correction)
    * [Language Error Correction](#Language-Error-Correction)
    * [Code Error Correction](#Code-Error-Correction)
  - [Demo](#Demo)
  - [Future Trends & Conclusion](#Future-Trends-&-Conclusion)
- [Datasets](#Datasets)
  - [Question Answering](#QA)
    * [Textbook Question Answering](#TQA)
    * [Math Word Problem Solving](#MWP)

  - [Question Construction](#QC)
  - [Automated Assessment](#AA)
    * [Automated Essay Scoring](#AES)
  - [Error Correction](#EC)
    * [Language Error Correction](#LEC)
    * [Code Error Correction](#CEC)
- [Citation](#Citation)

## Papers

### Introduction & Taxonomy

1. **Learn to explain: Multimodal reasoning via thought chains for science question answering**, NeurIPS (2022)

   *Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., Kalyan, A.* [[pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/11332b6b6cf4485b84afadb1352d3a9a-Paper-Conference.pdf)]

2. **Theoremqa: A theorem-driven question answering dataset**, arXiv preprint arXiv:2305.12524 (2023)

   *Chen, W., Yin, M., Ku, M., Wan, E., Ma, X., Xu, J., Xia, T., Wang, X., Lu, P.* [[pdf](https://arxiv.org/pdf/2305.12524.pdf)]

3. **Diverse and informative dialogue generation with context-specific commonsense knowledge awareness**, ACL (2020)

   *Wu, S., Li, Y., Zhang, D., Zhou, Y., Wu, Z.* [[pdf](https://aclanthology.org/2020.acl-main.515.pdf)]

4. **Learning sentence embeddings with auxiliary tasks for cross- domain sentiment classification**, EMNLP (2016)

   *Yu, J., Jiang, J.* [[pdf](https://aclanthology.org/D16-1023.pdf)]

5. **Complex Knowledge Base Question Answering: A Survey**, IEEE (2022)

   *Lan Y, He G, Jiang J.* [[pdf](https://arxiv.org/pdf/2108.06688.pdf)]

6. **Grammatical error correction: A survey of the state of the art**, CL 49(3) (2023)

   *Bryant, C., Yuan, Z., Muhammad, R., Qorib, Q., Cao, H., Ng, H., Briscoe, T.* [[pdf](https://watermark.silverchair.com/coli_a_00478.pdf?token=AQECAHi208BE49Ooan9kkhW_Ercy7Dm3ZL_9Cf3qfKAc485ysgAAAzowggM2BgkqhkiG9w0BBwagggMnMIIDIwIBADCCAxwGCSqGSIb3DQEHATAeBglghkgBZQMEAS4wEQQMxoWDz4FscdksKXXRAgEQgIIC7TcsL8DzAmdHWfbEqEaOfBvq8oZrSeSlG2IEj5_8uRFtgD3_KRnnsCNZHcQcbieqf6uDygNaA5vcIznP5WzdlI2HvuqzRke3py6xqtbtTQM_-WcZbKMY6FFeRdBdpcojgJjU7eTDCPvXuJIAPrRmmWpLCNu7YK4AsN1gXM8OlShhKG32hA1-2QNIN0DhgYyQVyagNs_ALMCvoA673tYwE_LnPiReH0GoMxMwuC3L4iRbSnnc8vh5HnjO31w4-g6Uv9DASFinxyXhRkefqtiL2I-qbwAsv1z9U695XE4T3HJQgjozggvrnW6B8vmzC7H3uB_WdPM2DHz2eOxFFhyCDjFrm5WWpvoiby9ekk9kaoVVzaFVpDZDG0vGpHx45cuCR33LhUYVLWvIGQs_2I5-1PNO0YV-6mdkhS5tjHO7BaemsdvlC89yQLXfMX6lqmhR277B74SiBjcctEK3GmbOYFCEBjGW0sLp60Dj-SfuUrLJ1_Pxxcq6eZdOxZZUJrH2T1U00vNyKjJP0zfVvU-pLyiL_rhHZ09dm4JtcEwpm7YWLrOxEJIVME_nDwHBMfX7FFXrfLj29My9Jbgg7UmglFMqefZmyhj3ibMwYl-u4KOujtwthzOfveJUBGMHWP3JmFdd4o_JBbfPmHXwNsOwLSTxW_TwhSZoJZHz6HQai9bHLszedfuES6JV5YNgUHX6xsL_eMJ465z1UpUnLs2WD6b9qSRmFUhW_E2IZ11Nra59itsdxuCzCTkVt6yFWGd7sUeu5tUCTODLnB4pjS-8b0L-eGsw8Aop-QPH8izwojystNg-kO0WOH2Gq_kp2rt6ProC3sk8Oxh8HG-mddcRZRcX0gPQ-zjeciS_vysyGnDlqohKzfqFhfzeN_WQSv8bpICPfBe0z7MLC8KtwsJka86PAmuur6g5-JzOPkq0JrUW-dNFr1_oe1EK_be61R8oZs7iw8lFrp4-0HlEW3HMvYAmQmQ5HTCvIrAmO7dg)]

7. **The gap of semantic parsing: A survey on automatic math word problem solvers**, TPAMI 42(9) (2019)

   *Zhang, D., Wang, L., Zhang, L., Dai, B.T., Shen, H.T.* [[link](https://ieeexplore.ieee.org/abstract/document/8703135)]

8. **Automated grading and feedback tools for programming education: A systematic review**, TOCE (2023)

​      *Messer, M., Brown, N.C.C., K ̈olling, M., Shi, M.* [[pdf](https://arxiv.org/pdf/2306.11722.pdf)]

9. **Adapting large language models for education: Foundational capabilities, potentials, and challenges**, arXiv preprint arXiv:2401.08664 (2023)

​      *Q. Li, L. Fu, W. Zhang, X. Chen, J. Yu, W. Xia, W. Zhang, R. Tang, and Y. Yu.* [[pdf](https://arxiv.org/pdf/2401.08664)]

10. **Large language models for education: A survey and outlook**, arXiv preprint arXiv:2403.18105(2024)

​      *S. Wang, T. Xu, H. Li, C. Zhang, J. Liang, J. Tang, P. S. Yu, and Q. Wen.* [[pdf](https://arxiv.org/pdf/2403.18105)]

11. **Information extraction from scientific paper using rhetorical classifier**, ICEEI(2011)

​      *M. L. Khodra, D. H. Widyantoro, E. Aziz, and R. T. Bambang.* [[linking](https://ieeexplore.ieee.org/document/6021634)]

12. **Conversational agents for information retrieval in the education domain: A usercentered design investigation**, HCI(2022)

​      *A. Schmitt, T. Wambsganss, and J. M. Leimeister.* [[linking](https://dl.acm.org/doi/10.1145/3555587)]

13. **Multi-source education knowledge graph construction and fusion for college curricula**, ICALT(2023)

​      *L. Cripwell, J. Legrand, and C. Gardent.* [[pdf](https://arxiv.org/pdf/2305.04567)]

14. **Context-aware document simplification**, ACL(2023)

​      *S. Wang, T. Xu, H. Li, C. Zhang, J. Liang, J. Tang, P. S. Yu, and Q. Wen.* [[pdf](https://aclanthology.org/2023.findings-acl.834.pdf)]

15. **Diffusion-lm improves controllable text generation**, NeurIPS(2022)

​      *X. Li, J. Thickstun, I. Gulrajani, P. S. Liang, and T. B. Hashimoto.* [[pdf](https://arxiv.org/pdf/2205.14217)]



### Question Answering

#### Textbook Question Answering

1. **Learn to explain: Multimodal reasoning via thought chains for science question answering**, NeurIPS (2022)

   *Lu, P., Mishra, S., Xia, T., Qiu, L., Chang, K.-W., Zhu, S.-C., Tafjord, O., Clark, P., Kalyan, A.* [[pdf](https://proceedings.neurips.cc/paper_files/paper/2022/file/11332b6b6cf4485b84afadb1352d3a9a-Paper-Conference.pdf)]

2. **Theoremqa: A theorem-driven question answering dataset**, arXiv preprint arXiv:2305.12524 (2023)

   *Chen, W., Yin, M., Ku, M., Wan, E., Ma, X., Xu, J., Xia, T., Wang, X., Lu, P.* [[pdf](https://arxiv.org/pdf/2305.12524.pdf)]

3. **Few-shot question answering by pretraining span selection**, arXiv preprint arXiv:2101.00438 (2021)

   *O. Ram, Y. Kirstain, J. Berant, A. Globerson, and O. Levy.* [[pdf](https://arxiv.org/pdf/2101.00438)]

4. **From clozing to comprehending: Retrofftting pre-trained language model to pre-trained machine reader**, arXiv preprint arXiv:2212.04755 (2022)

   *W. Xu, X. Li, W. Zhang, M. Zhou, L. Bing, W. Lam, and L. Si.* [[pdf](https://arxiv.org/pdf/2212.04755)]

5. **Domain-agnostic questionanswering with adversarial training**, (2019)

   *S. Lee, D. Kim, and J. Park.* [[pdf](https://aclanthology.org/D19-5826.pdf)]

6. **Reverse-engineering visualizations: Recovering visual encodings from chart images**, Computer graphics forum (2017)

   *J. Poco and J. Heer.* [[pdf](https://idl.cs.washington.edu/files/2017-ReverseEngineeringVis-EuroVis.pdf)]

7. **Dvqa: Understanding data visualizations via question answering**, CVPR (2018)

   *Kafle, K., Price, B., Cohen, S., Kanan, C.* [[pdf](https://openaccess.thecvf.com/content_cvpr_2018/papers/Kafle_DVQA_Understanding_Data_CVPR_2018_paper.pdf)]

8. **T-SciQ: Teaching Multimodal Chain-of-Thought Reasoning via Large Language Model Signals for Science Question Answering**, CGF (2017)

   *Wang, L., Hu, Y., He, J., Xu, X., Liu, N., Liu, H., Shen, H.T.* [[pdf](https://arxiv.org/pdf/2305.03453.pdf)]

9. **Augmenting black-box llms with medical textbooks for clinical question answering**, arXiv preprint arXiv:2309.02233 (2023)

   *Wang, Y., Ma, X., Chen, W.* [[pdf](https://arxiv.org/pdf/2309.02233.pdf)]

10. **Visual Instruction Tuning**, (2023)

    *H. Liu, C. Li, Q. Wu, and Y. J. Lee.* [[pdf](https://arxiv.org/pdf/2304.08485.pdf)]

11. **Enhancing textbook question answering task with large language models and retrieval augmented generation**, arXiv e-prints (2024)

    *H. Abdulrahman Alawwad, A. Alhothali, U. Naseem, A. Alkhathlan, and A. Jamal.* [[pdf](https://arxiv.org/pdf/2402.05128)]

12. **Spatialsemantic collaborative graph network for textbook question answering**, IEEE TCSVT (2023)

    *Y. Wang, B. Wei, J. Liu, Q. Lin, L. Zhang, and Y. Wu.* [[linking](https://ieeexplore.ieee.org/document/9996417)]

13. **Isaaq–mastering textbook questions with pre-trained transformers and bottom-up and topdown attention**, arXiv preprint arXiv:2010.00562 (2020)

    *J. M. Gomez-Perez and R. Ortega.* [[pdf](https://arxiv.org/pdf/2010.00562.pdf)]

14. **GeoSQA: A benchmark for scenario-based question answering in the geography domain at high school level**, EMNLP-IJCNLP (2019)

    *Z. Huang, Y. Shen, X. Li, Y. Wei, G. Cheng, L. Zhou, X. Dai, and Y. Qu.* [[pdf](https://aclanthology.org/D19-1597.pdf)]

15. **Combining retrieval, statistics, and inference to answer elementary science questions**,  AAAI (2016)

    *Q. Chen, X. Zhu, Z.-H. Ling, S. Wei, H. Jiang, and D. Inkpen.* [[linking](https://ojs.aaai.org/index.php/AAAI/article/view/10325)]

16. **Enhanced LSTM for natural language inference**, ACL (2017)

    *Chen, W., Yin, M., Ku, M., Wan, E., Ma, X., Xu, J., Xia, T., Wang, X., Lu, P.* [[pdf](https://arxiv.org/pdf/1609.06038)]

17. **mplug-owl3: Towards long image-sequence understanding in multi-modal large language models**,  (2024)

    *J. Ye, H. Xu, H. Liu, A. Hu, M. Yan, Q. Qian, J. Zhang, F. Huang, and J. Zhou.* [[pdf](https://arxiv.org/pdf/2408.04840)]

18. **Boosting the power of small multimodal reasoning models to match larger models with self-consistency training**, ECCV (2023)

    *C. Tan, J. Wei, Z. Gao, L. Sun, S. Li, X. Yang, and S. Z. Li.* [[pdf](https://arxiv.org/pdf/2311.14109)]

19. **Honeybee: Localityenhanced projector for multimodal llm**, CVPR (2024)

    *J. Cha, W. Kang, J. Mun, and B. Roh.* [[pdf](https://arxiv.org/pdf/2312.06742)]

20. **What disease does this patient have? a large-scale open domain question answering dataset from medical exams**, arXiv preprint arXiv:2009.13081 (2020)

    *D. Jin, E. Pan, N. Oufattole, W.-H. Weng, H. Fang, and P. Szolovits.* [[pdf](https://arxiv.org/pdf/2009.13081.pdf)]

21. **Variational open-domain question answering**, ICML (2023)

    *V. Lie´vin, A. G. Motzfeldt, I. R. Jensen, and O. Winther.* [[pdf](https://arxiv.org/pdf/2210.06345)]

22. **Multimodal table understanding**, ACL (2024)

    *M. Zheng, X. Feng, Q. Si, Q. She, Z. Lin, W. Jiang, and W. Wang.* [[pdf](https://arxiv.org/pdf/2406.08100)]

23. **Education question answering systems: a survey**, IMECS (2021)

    *T. G. Soares, A. Azhari, N. Rokhman, and E. Wonarko.* [[pdf](https://www.iaeng.org/publication/IMECS2021/IMECS2021_pp24-34.pdf)]

24. **Are you smarter than a sixth grader? textbook question answering for multimodal machine comprehension**, MECS (2021)

    *Kembhavi, A., Seo, M., Schwenk, D., Choi, J., Farhadi, A., Hajishirzi, H.* [[pdf](https://openaccess.thecvf.com/content_cvpr_2017/papers/Kembhavi_Are_You_Smarter_CVPR_2017_paper.pdf)]

25. **A diagram is worth a dozen images**, ECCV (2016)

    *Kembhavi, A., Salvato, M., Kolve, E., Seo, M., Hajishirzi, H., Farhadi, A.* [[link](https://link.springer.com/chapter/10.1007/978-3-319-46493-0_15)]

26. **Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering**, CHIL (2022)

    *Pal, A., Umapathi, L.K., Sankarasubbu, M.* [[pdf](https://proceedings.mlr.press/v174/pal22a/pal22a.pdf)]

27. **An image is worth 16x16 words: Transformers for image recognition at scale**, arXiv preprint arXiv:2010.11929 (2020)

    *Dosovitskiy, A., Beyer, L., Kolesnikov, A., Weissenborn, D., Zhai, X., Unterthiner, T., Dehghani, M.,Minderer, M., Heigold, G., Gelly, S., et al.* [[pdf](https://arxiv.org/pdf/2010.11929.pdf)]

28. **Dynamic fusion with intra-and inter-modality attention flow for visual quetion answering**, CVPR (2019)

    *Gao, P., Jiang, Z., You, H., Lu, P., Hoi, S.C., Wang, X., Li, H.* [[pdf](https://openaccess.thecvf.com/content_CVPR_2019/papers/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.pdf)]

29. **Transform-retrieve-generate: Natural language-centric outside-knowledge visual question answering**, CVPR (2022)

    *Gao, F., Ping, Q., Thattai, G., Reganti, A., Wu, Y.N., Natarajan, P.* [[pdf](https://openaccess.thecvf.com/content/CVPR2022/papers/Gao_Transform-Retrieve-Generate_Natural_Language-Centric_Outside-Knowledge_Visual_Question_Answering_CVPR_2022_paper.pdf)]

30. **Vqa: Visual question answering**, CCV (2015)

    *Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh, D.* [[pdf](https://openaccess.thecvf.com/content_iccv_2015/papers/Antol_VQA_Visual_Question_ICCV_2015_paper.pdf)]

31. **Ask your neurons: A neural-based approach to answering questions about images**, CCV (2015)

    *Malinowski, M., Rohrbach, M., Fritz, M.* [[pdf](https://openaccess.thecvf.com/content_iccv_2015/papers/Malinowski_Ask_Your_Neurons_ICCV_2015_paper.pdf)]



#### Math Word Problem Solving

1. **Translating a math word problem to a expression tree**,  (2018)

   *Wang, L., Wang, Y., Cai, D., Zhang, D., Liu, X.* [[pdf](https://aclanthology.org/D18-1132.pdf)]

2. **Semantically-aligned equation generation for solving and reasoning math word problems**, arXiv preprint arXiv:1811.00720 (2019)

   *Chiang, T.-R., Chen, Y.-N.* [[pdf](https://arxiv.org/pdf/1811.00720.pdf)]

3. **Tree-structured decoding for solving math word problems**, EMNLP-IJCNLP (2019)

   *Liu, Q., Guan, W., Li, S., Kawahara, D.* [[pdf](https://aclanthology.org/D19-1241.pdf)]

4. **A goal-driven tree-structured neural model for math word problems**, jcai (2019)

   *Xie, Z., Sun, S.* [[pdf](https://www.ijcai.org/proceedings/2019/0736.pdf)]

5. **Graph-to-tree learning for solving math word problems**, ACL (2020)

   *Zhang, J., Wang, L., Lee, R.K.-W., Bin, Y., Wang, Y., Shao, J., Lim, E.-P.* [[pdf](https://aclanthology.org/2020.acl-main.362.pdf)]

6. **Hms: A hierarchical solver with dependency-enhanced understanding for math word problem**, AAAI (2021)

   *Lin, X., Huang, Z., Zhao, H., Chen, E., Liu, Q., Wang, H., Wang, S.* [[link](https://ojs.aaai.org/index.php/AAAI/article/view/16547)]

7. **Learning by fixing: Solving math word problems with weak supervision**, AAAI (2021)

   *Hong, Y., Li, Q., Ciao, D., Huang, S., Zhu, S.-C.* [[pdf](https://arxiv.org/pdf/2012.10582.pdf)]

8. **Teacher-student networks with multiple decoders for solving math word problem**, JCAI (2020)

   *Zhang, J., Lee, R.K.-W., Lim, E.-P., Qin, W., Wang, L., Shao, J., Sun, Q.* [[pdf](https://www.ijcai.org/proceedings/2020/0555.pdf)]

9. **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models**, JCAI (2020)

   *Zhang, J., Lee, R.K.-W., Lim, E.-P., Qin, W., Wang, L., Shao, J., Sun, Q.* [[pdf](https://arxiv.org/pdf/2201.11903.pdf)]

10. **Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large language models**, arXiv preprint arXiv:2305.04091 (2023)

    *Wei, J., Wang, X., Schuurmans, D., Bosma, M., Ichter, B., Xia, F., Chi, E., Le,
    Q., Zhou, D.* [[pdf](https://arxiv.org/pdf/2305.04091.pdf)]

11. **Automatic chain of thought prompting in large language models**, arXiv preprint arXiv:2210.03493 (2022)

    *Zhang, Z., Zhang, A., Li, M., Smola, A.* [[pdf](https://arxiv.org/pdf/2210.03493.pdf)]

12. **Least-to-most prompting enables complex reasoning in large language models**, arXiv preprint arXiv:2205.10625 (2022)

    *Zhou, D., Sch ̈arli, N., Hou, L., Wei, J., Scales, N., Wang, X., Schuurmans, D., Bousquet, O., Le, Q., Chi, E.* [[pdf](https://arxiv.org/pdf/2205.10625.pdf)]

13. **Progressive-hint prompting improves reasoning in large language models**, arXiv preprint arXiv:2304.09797 (2023)

    *Zheng, C., Liu, Z., Xie, E., Li, Z., Li, Y.* [[pdf](https://arxiv.org/pdf/2304.09797.pdf)]

14. **Chameleon: Plug-and-play compositional reasoning with large language models**, (2023)

    *P. Lu, B. Peng, H. Cheng, M. Galley, K.-W. Chang, Y. N. Wu, S.- C. Zhu, and J. Gao* [[pdf](https://arxiv.org/pdf/2304.09842)]

15. **Math word problem generation via disentangled memory retrieval**, TKDD (2024)

    *W. Qin, X. Wang, Z. Hu, L. Wang, Y. Lan, and R. Hong.* [[linking](https://dl.acm.org/doi/10.1145/3639569)]

16. **Towards generating math word problems from equations and topics**, ICNLG (2019)

    *Q. Zhou and D. Huang.* [[pdf](hhttps://aclanthology.org/W19-8661.pdf)]

17. **EPT-X: An expressionpointer transformer model that generates eXplanations for numbers**, ACL (2022)

    *B. Kim, K. S. Ki, S. Rhim, and G. Gweon.* [[pdf](https://aclanthology.org/2022.acl-long.305.pdf)]

18. **Generating equation by utilizing operators : GEO model**, COLING (2020)

    *K. S. Ki, D. Lee, B. Kim, and G. Gweon.* [[pdf](https://aclanthology.org/2020.coling-main.38.pdf)]

19. **Teaching-inspired integrated prompting framework: A novel approach for enhancing reasoning in large language models**,  (2024)

    *W. Tan, D. Chen, J. Xue, Z. Wang, and T. Chen.* [[pdf](https://arxiv.org/pdf/2410.08068)]

20. **Multi-view reasoning: Consistent contrastive learning for math word problem**, EMNLP (2022)

    *W. Zhang, Y. Shen, Y. Ma, X. Cheng, Z. Tan, Q. Nong, and W. Lu.* [[pdf](https://arxiv.org/pdf/2210.11694)]

21. **Generate & rank: A multi-task framework for math word problems**, ACL (2021)

    *J. Shen, Y. Yin, L. Li, L. Shang, X. Jiang, M. Zhang, and Q. Liu.* [[pdf](https://arxiv.org/pdf/2109.03034)]

22. **ELASTIC: Numerical reasoning with adaptive symbolic compiler**, NeurIPS (2022)

    *J. Zhang and Y. Moshfeghi.* [[pdf](https://arxiv.org/pdf/2210.10105)]

23. **Toolformer: Language models can teach themselves to use tools**, NeurIPS (2023)

    *T. Schick, J. Dwivedi-Yu, R. Dessi, R. Raileanu, M. Lomeli, E. Hambro, L. Zettlemoyer, N. Cancedda, and T. Scialom.* [[pdf](https://arxiv.org/pdf/2302.04761)]

24. **Achieving >97% on GSM8K: Deeply Understanding the Problems Makes LLMs Better Solvers for Math Word Problems**, arXiv preprint arXiv:2404.14963 (2024)

    *. Zhong, K. Wang, Z. Xu, J. Liu, L. Ding, and B. Du,.* [[pdf](https://arxiv.org/pdf/2404.14963.pdf)]

25. **Aggregating multiple heuristic signals as supervision for unsupervised automated essay scoring**, ACL (2023)

    *C. Wang, Z. Jiang, Y. Yin, Z. Cheng, S. Ge, and Q. Gu.* [[pdf](https://aclanthology.org/2023.acl-long.782.pdf)]

26. **Towards efffcient visual-language alignment of the q-former for visual reasoning tasks**,  (2024)

    *S. Kim, A. Lee, J. Park, A. Chung, J. Oh, and J.-Y. Lee.* [[pdf](https://arxiv.org/pdf/2410.09489)]

27. **Multimodal table understanding**, ACL (2024)

    *M. Zheng, X. Feng, Q. Si, Q. She, Z. Lin, W. Jiang, and W. Wang.* [[pdf](https://arxiv.org/pdf/2406.08100)]

28. **How well do computers solve math word problems? large-scale dataset construction and evaluation**, ACL (2016)

​       *Liu, H., Li, C., Wu, Q., Lee, Y.J.* [[pdf](https://aclanthology.org/P16-1084.pdf)]

29. **Annotating derivations: A new evaluation strategy and dataset for algebra word problems**, arXiv preprint arXiv:11609.07197 (2016)

​      *Upadhyay, S., Chang, M.-W.* [[pdf](https://arxiv.org/pdf/11609.07197.pdf)]

30. **Deep neural solver for math word problems**, EMNLP (2017)

​     *Wang, Y., Liu, X., Shi, S.* [[pdf](https://aclanthology.org/D17-1088.pdf)]

31. **MathQA: Towards interpretable math word problem solving with operation-based formalisms**,  (2019)

​     *Amini, A., Gabriel, S., Lin, S., Koncel-Kedziorski, R., Choi, Y., Hajishirzi, H.* [[pdf](https://aclanthology.org/N19-1245.pdf)]

32. **A diverse corpus for evaluating and developing English math word problem solvers**,  (2020)

​     *Miao, S.-y., Liang, C.-C., Su, K.-Y.* [[pdf](https://arxiv.org/ftp/arxiv/papers/2106/2106.15772.pdf)]

33. **Training Verifiers to Solve Math Word Problems**,  (2021)

​     *Cobbe, K., Kosaraju, V., Bavarian, M., Chen, M., Jun, H., Kaiser, L., Plappert, M., Tworek, J., Hilton, J., Nakano,     R., Hesse, C., Schulman, J.* [[pdf](https://arxiv.org/pdf/2110.14168.pdf)]

34. **Iconqa: A new benchmark for abstract diagram understanding and visual language reasoning**,  (2021)

​     *Lu, P., Qiu, L., Chen, J., Xia, T., Zhao, Y., Zhang, W., Yu, Z., Liang, X., Zhu, S.-C.* [[pdf](https://arxiv.org/pdf/2110.13214.pdf)]

35. **Dynamic prompt learning via policy gradient for semi-structured mathematical reasoning**, arXiv preprint arXiv:2209.14610 (2022)

​     *Lu, P., Qiu, L., Chang, K.-W., Wu, Y.N., Zhu, S.-C., Rajpurohit, T., Clark, P., Kalyan, A.* [[pdf](https://arxiv.org/pdf/2209.14610.pdf)]

36. **The gap of semantic parsing: A survey on automatic math word problem solvers**, TPAMI (2020)

​     *Zhang, D., Wang, L., Zhang, L., Dai, B.T., Shen, H.T.* [[link](https://ieeexplore.ieee.org/abstract/document/8703135)]

37. **Tora: A tool-integrated reasoning agent for mathematical problem solving**, arXiv preprint arXiv:2309.17452 (2023)

​     *Gou, Z., Shao, Z., Gong, Y., Yang, Y., Huang, M., Duan, N., Chen, W., et al.* [[pdf](https://arxiv.org/pdf/2309.17452.pdf)]



### Question Construction

#### Question Generation

1. **Difficulty controllable generation of reading comprehension questions**, arXiv preprint arXiv:1807.03586 (2018)

   *Gao, Y., Bing, L., Chen, W., Lyu, M.R., King, I.* [[pdf](https://arxiv.org/pdf/1807.03586.pdf)]

2. **Guiding the growth: Difficulty-controllable question generation through step-by-step rewriting**, arXiv preprint arXiv:2105.11698 (2021)

   *Cheng, Y., Li, S., Liu, B., Zhao, R., Li, S., Lin, C., Zheng, Y.* [[pdf](https://arxiv.org/pdf/2105.11698.pdf)]

3. **Difficulty-controllable neural question generation for reading comprehension using item response theory**, BEA (2023)

   *Uto, M., Tomikawa, Y., Suzuki, A.* [[pdf](https://aclanthology.org/2023.bea-1.10.pdf)]

4. **Bloom’s taxonomy: Original and revised**,  (2005)

   *M. Forehand et al.*

5. **Towards automated multiple choice question generation and evaluation: aligning with bloom’s taxonomy**, AIED (2024)

   *K. Hwang, K. Wang, M. Alomair, F.-S. Choa, and L. K. Chen.* [[linking](https://link.springer.com/chapter/10.1007/978-3-031-64299-9_35)]

6. **I do not understand what i cannot define: Automatic question generation with pedagogically-driven content selection**, arXiv preprint arXiv:2110.04123 (2021)

   *Steuer, T., Filighera, A., Meuser, T., Rensing, C.* [[pdf](https://arxiv.org/pdf/2110.04123.pdf)]

7. **Diverse content selection for educational question generation**, EACL (2023)

   *Hadifar, A., Bitew, S.K., Deleu, J., Hoste, V., Develder, C., Demeester, T.* [[pdf](https://aclanthology.org/2023.eacl-srw.13.pdf)]

8. **Evaluating reading comprehension exercises generated by llms: A showcase of chatgpt in education applications**, BEA (2023)

   *C. Xiao, S. X. Xu, K. Zhang, Y. Wang, and L. Xia.* [[pdf](https://aclanthology.org/2023.bea-1.52.pdf)]

9. **Question generation for adaptive education**, arXiv preprint arXiv:2106.04262 (2021)

   *Srivastava, M., Goodman, N.* [[pdf](https://arxiv.org/pdf/2106.04262.pdf)]

10. **Difficulty-controlled question generation in adaptive education for few-shot learning**, ADMA (2023)

    *Wang, Y., Li, L.* [[link](https://link.springer.com/chapter/10.1007/978-3-031-46677-9_40)]

11. **Automatic question generation and answer assessment: A survey**, Research and Practice in Technology Enhanced Learning (2021)

    *B. Das, M. Majumder, S. Phadikar, and A. A. Sekh.* [[link](https://link.springer.com/article/10.1186/s41039-021-00151-1)]

12. **A feasibility study of answer-agnostic question generation for education**, arXiv preprint arXiv:2203.08685 (2022)

    *Dugan, L., Miltsakaki, E., Upadhyay, S., Ginsberg, E., Gonzalez, H., Choi, D., Yuan, C., Callison-Burch, C.* [[pdf](https://arxiv.org/pdf/2203.08685.pdf)]

13. **Question answering and question generation as dual tasks**, arXiv preprint arXiv:1706.02027 (2017)

    *Tang, D., Duan, N., Qin, T., Yan, Z., Zhou, M.* [[pdf](https://arxiv.org/pdf/1706.02027.pdf)]

14. **Crowdsourcing multiple choice science questions**, arXiv preprint arXiv:1707.06209 (2017)

    *Welbl, J., Liu, N.F., Gardner, M.* [[pdf](https://arxiv.org/pdf/1707.06209.pdf)]

15. **Race: Large-scale reading comprehension dataset from examinations**, arXiv preprint arXiv:1704.04683 (2017)

    *Lai, G., Xie, Q., Liu, H., Yang, Y., Hovy, E.* [[pdf](https://arxiv.org/pdf/1704.04683.pdf)]

16. **Towards data-effective educational question generation with prompt-based learning**, SAI (2023)

    *Wu, Y., Nouri, J., Megyesi, B., Henriksson, A., Duneld, M., Li, X.* [[link](https://link.springer.com/chapter/10.1007/978-3-031-37717-4_11)]

17. **Eqg-race: Examination-type question generation**, AAAI, vol. 35 (2021)

    *Jia, X., Zhou, W., Sun, X., Wu, Y.* [[pdf](https://arxiv.org/pdf/2012.06106.pdf)]

18. **Investigating educational and noneducational answer selection for educational question generation**, EEE Access (2022)

    *Steuer, T., Filighera, A., Tregel, T.* [[pdf](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9791321)]

19. **Educational question generation of children storybooks via question type distribution learning and event-centric summarization**, arXiv preprint arXiv:2203.14187 (2022)

    *Zhao, Z., Hou, Y., Wang, D., Yu, M., Liu, C., Ma, X.* [[pdf](https://arxiv.org/pdf/2203.14187.pdf)]

20. **Learningq: a large-scale dataset for educational question generation**, CWSM, vol. 12 (2018)

    *Chen, G., Yang, J., Hauff, C., Houben, G.-J.* [[pdf](https://ojs.aaai.org/index.php/ICWSM/article/view/14987/14837)]

21. **Khanq: A dataset for generating deep questions in education**, CCL (2022)

    *Gong, H., Pan, L., Hu, H.* [[pdf](https://aclanthology.org/2022.coling-1.518.pdf)]

22. **Eduqg: A multi-format multiple-choice dataset for the educational domain**, IEEE Access (2023)

    *Hadifar, A., Bitew, S.K., Deleu, J., Develder, C., Demeester, T.* [[pdf](https://arxiv.org/pdf/2210.06104.pdf)]

23. **Harnessing the power of prompt-based techniques for generating school-level questions using large language models**, FIRE (2023)

    *S. Maity, A. Deroy, and S. Sarkar.* [[pdf](https://arxiv.org/pdf/2312.01032)]

24. **Scalable educational question generation with pre-trained language models**, AIED (2023)

    *S. Bulathwela, H. Muse, and E. Yilmaz.* [[pdf](https://arxiv.org/pdf/2305.07871)]

25. **Unsupervised domain adaptation for question generation with domain data selection and self-training**, NAACL(2022)

    *P. Zhu and C. Hauff.* [[pdf](https://aclanthology.org/2022.findings-naacl.183.pdf)]

26. **Simplifying paragraph-level question generation via transformer language models**, PRICAI (2021)

    *L. E. Lopez, D. K. Cruz, J. C. B. Cruz, and C. Cheng.* [[pdf](https://arxiv.org/pdf/2005.01107)]

27. **A bert-based distractor generation scheme with multi-tasking and negative answer training strategies**, arXiv preprint arXiv:2010.05384 (2020)

    *H.-L. Chung, Y.-H. Chan, and Y.-C. Fan.* [[pdf](https://arxiv.org/pdf/2010.05384)]

28. **Learning to ask: Neural question generation for reading comprehension**, arXiv preprint arXiv:1705.00106 (2017)

    *X. Du, J. Shao, and C. Cardie.* [[pdf](https://arxiv.org/pdf/1705.00106)]

29. **Addressing the rare word problem in neural machine translation**, arXiv preprint arXiv:1410.8206 (2014)

    *M.-T. Luong, I. Sutskever, Q. V. Le, O. Vinyals, and W. Zaremba.* [[pdf](https://arxiv.org/pdf/1410.8206)]

30. **Good question! statistical ranking for question generation**, NAACL (2010)

    *M. Heilman and N. A. Smith.* [[pdf](https://aclanthology.org/N10-1086.pdf)]

31. **Exploring the limits of transfer learning with a uniffed text-to-text transformer**, J. Mach. Learn. Res. (2020)

    *C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu.* [[pdf](https://arxiv.org/pdf/1910.10683)]

32. **Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension**, arXiv preprint arXiv:1910.13461 (2019)

    *M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy, V. Stoyanov, and L. Zettlemoyer.* [[pdf](https://arxiv.org/pdf/1910.13461)]

33. **Unified language model pre-training for natural language understanding and generation**, NeurIPS (2019)

    *L. Dong, N. Yang, W. Wang, F. Wei, X. Liu, Y. Wang, J. Gao, M. Zhou, and H.-W. Hon.* [[pdf](https://arxiv.org/pdf/1905.03197)]

34. **Multilingual denoising pre-training for neural machine translation**, arXiv preprint arXiv:2001.08210 (2020)

    *Y. Liu.* [[pdf](https://arxiv.org/pdf/2001.08210)]



#### Distractor Generation

1. **Distractor generation for multiple-choice questions with predictive prompting and large language models**, arXiv preprint arXiv:2307.16338 (2023)

   *Bitew, S.K., Deleu, J., Develder, C., Demeester, T.* [[pdf](https://arxiv.org/pdf/2307.16338.pdf)]

2. **Multisource soft labeling and hard negative sampling for retrieval distractor ranking**, IEEE TLT (2023)

   *J. Wang, W. Rong, J. Bai, Z. Sun, Y. Ouyang, and Z. Xiong.* [[linking](https://ieeexplore.ieee.org/document/10288270)]

3. **Enhancing distractor generation for multiple-choice questions with retrieval augmented pretraining and knowledge graph integration **, (2024)

   *H.-C. Yu, Y.-A. Shih, K.-M. Law, K.-Y. Hsieh, Y.-C. Cheng, H.- C. Ho, Z.-A. Lin, W.-C. Hsu, and Y.-C. Fan.* [[pdf](https://arxiv.org/pdf/2406.13578)]

4. **Generating distractors for reading comprehension questions from real examinations**, AAAI, vol. 33 (2019)

   *Gao, Y., Bing, L., Li, P., King, I., Lyu, M.R.* [[pdf](https://arxiv.org/pdf/1809.02768)]

5. **Can we learn question, answer, and distractors all from an image? a new task for multiple-choice visual question answering**, LREC-COLING (2024)

   *W. Ding, Y. Zhang, J. Wang, A. Jatowt, and Z. Yang.* [[pdf](https://aclanthology.org/2024.lrec-main.254.pdf)]

6. **Distractor generation in multiple-choice tasks: A survey of methods, datasets, and evaluation**, arXiv preprint arXiv:2402.01512 (2024)

   *E. Alhazmi, Q. Z. Sheng, W. E. Zhang, M. Zaib, and A. Alhazmi.* [[pdf](https://arxiv.org/pdf/2402.01512.pdf)]

7. **Distractor generation using generative and discriminative capabilities of transformer-based models**, LREC-COLING (2024)

   *S. Taslimipoor, L. Benedetto, M. Felice, and P. Buttery.* [[pdf](https://aclanthology.org/2024.lrec-main.452.pdf)]

8. **Unsupervised distractor generation via large language model distilling and counterfactual contrastive decoding**, arXiv preprint arXiv:2406.01306 (2024)

   *F. Qu, H. Sun, and Y. Wu.* [[pdf](https://arxiv.org/pdf/2406.01306.pdf)]

9. **Crowdsourcing multiple choice science questions**, arXiv preprint arXiv:1707.06209 (2017)

   *Welbl, J., Liu, N.F., Gardner, M.* [[pdf](https://arxiv.org/pdf/1910.08832)]

10. **Distractor generation for multiple choice questions using learning to rank**, BEA (2018)

    *Liang, C., Yang, X., Dave, N., Wham, D., Pursel, B., Giles, C.L.* [[pdf](https://aclanthology.org/W18-0533.pdf)]

11. **Learning to reuse distractors to support multiple choice question generation in education**, IEEE TLT (2022)

    *S. K. Bitew, A. Hadifar, L. Sterckx, J. Deleu, C. Develder, and T. Demeester.* [[pdf]()]

12. **mt5: A massively multilingual pre-trained text-to-text transformer**, arXiv preprint arXiv:2010.11934 (2020)

    *L. Xue.* [[pdf](https://arxiv.org/pdf/2010.11934)]

13. **Automated question generation methods for intelligent english learning systems and its evaluation**,  ICCE (2004)

    *H. Kunichika, T. Katayama, T. Hirashima, and A. Takeuchi.* [[linking](https://www.researchgate.net/publication/228948179_Automated_question_generation_methods_for_intelligent_English_learning_systems_and_its_evaluation)]

14. **Identifying where to focus in reading comprehension for neural question generation**, EMNLP (2017)

    *X. Du and C. Cardie.* [[pdf](https://aclanthology.org/D17-1219.pdf)]

15. **Neural generation of diverse questions using answer focus, contextual and linguistic features**, arXiv preprint arXiv:1809.02637 (2018)

    *V. Harrison and M. Walker.* [[pdf](https://arxiv.org/pdf/1809.02637)]

16. **Question generation using sequence-to-sequence model with semantic role labels**,  EACL (2022)

    *A. Naeiji.* [[pdf](https://aclanthology.org/2023.eacl-main.207.pdf)]

17. **Multiqg-ti: Towards question generation from multi-modal sources**, arXiv preprint arXiv:2307.04643 (2023)

    *Z. Wang and R. Baraniuk.* [[pdf](https://arxiv.org/pdf/2307.04643)]

18. **Multi-task learning with language modeling for question generation**, arXiv preprint arXiv:1908.11813 (2019)

    *W. Zhou, M. Zhang, and Y. Wu.* [[pdf](https://arxiv.org/pdf/1908.11813)]

19. **Natural question generation with reinforcement learning based graph-to-sequence model**, arXiv preprint arXiv:1910.08832 (2019)

    *Y. Chen, L. Wu, and M. J. Zaki.* [[pdf](https://arxiv.org/pdf/1910.08832)]

20. **A recurrent bert-based model for question generation**, MRQA (2019)

    *Y.-H. Chan and Y.-C. Fan.* [[pdf](https://aclanthology.org/D19-5821.pdf)]

21. **Towards human-like educational question generation with large language models**, AIED (2022)

    *Z. Wang, J. Valdez, D. Basu Mallick, and R. G. Baraniuk.* [[linking](https://link.springer.com/chapter/10.1007/978-3-031-11644-5_13)]

22. **Machine comprehension by text-to-text neural question generation**, arXiv preprint arXiv:1705.02012 (2017)

    *X. Yuan, T. Wang, C. Gulcehre, A. Sordoni, P. Bachman, S. Subramanian, S. Zhang, and A. Trischler.* [[pdf](https://arxiv.org/pdf/1705.02012)]

23. **Answer-focused and position-aware neural question generation**, EMNLP (2018)

    *X. Sun, J. Liu, Y. Lyu, W. He, Y. Ma, and S. Wang.* [[pdf](hhttps://aclanthology.org/D18-1427.pdf)]

24. **Improving question generation with sentence-level semantic matching and answer position inferring**, AAAI (2020)

    *X. Ma, Q. Zhu, Y. Zhou, and X. Li.* [[pdf](https://arxiv.org/pdf/1912.00879)]

25. **Few-shot is enough: exploring chatgpt prompt engineering method for automatic question generation in english education**, Education and Information Technologies (2024)

    *U. Lee, H. Jung, Y. Jeon, Y. Sohn, W. Hwang, J. Moon, and H. Kim.* [[linking](https://link.springer.com/article/10.1007/s10639-023-12249-8)]

26. **Harnessing the power of prompt-based techniques for generating school-level questions using large language models**, FIRE (2023)

    *S. Maity, A. Deroy, and S. Sarkar.* [[pdf](https://arxiv.org/pdf/2312.01032)]

27. **Automatic distractor generation for multiple choice questions in standard tests**, arXiv preprint arXiv:2011.13100 (2020)

    *Z. Qiu, X. Wu, and W. Fan.* [[pdf](https://aclanthology.org/2020.coling-main.189.pdf)]

28. **Computer-aided generation of multiple-choice tests**, HLT-NAAC (2003)

    *Mitkov, R., et al.* [[pdf](https://aclanthology.org/W03-0203.pdf)]

29. **Automatic question generation for vocabulary assessment**, HLT/EMNLP (2005)

    *Brown, J., Frishkoff, G., Eskenazi, M.* [[pdf](https://aclanthology.org/H05-1103.pdf)]



### Automated Assessment

#### Automated Essay Scoring

1. **Modeling thesis clarity in student essays**, ACL (2013)

   *Persing, I., Ng, V.* [[pdf](https://aclanthology.org/P13-1026.pdf)]

2. **Modeling prompt adherence in student essays**, ACL (2014)

   *Persing, I., Ng, V.* [[pdf](https://aclanthology.org/P14-1144.pdf)]

3. **A multi-task automated assessment system for essay scoring**, AIED (2024)

   *Jiang, Z., Gao, T., Yin, Y., Liu, M., Yu, H., Cheng, Z., Gu, Q.* [[linking](https://link.springer.com/chapter/10.1007/978-3-031-64299-9_22)]

4. **Improving domain generalization for prompt-aware essay scoring via disentangled representation learning**, ACL (2023)

   *S. Chen, Y. Lan, and Z. Yuan.* [[pdf](https://aclanthology.org/2023.acl-long.696.pdf)]

5. **Learning from graph propagation via ordinal distillation for one-shot automated essay scoring**, WWW (2021)

   *Jiang, Z., Liu, M., Yin, Y., Yu, H., Cheng, Z., Gu, Q.* [[link](https://dl.acm.org/doi/10.1145/3442381.3450017)]

6. **PMAES: Prompt-mapping contrastive learning for cross-prompt automated essay scoring**, ACL (2023)

   *Y. Chen and X. Li.* [[link](https://aclanthology.org/2023.acl-long.83.pdf)]

7. **Aggregating multiple heuristic signals as supervision for unsupervised automated essay scoring**, ACL (2023)

   *C. Wang, Z. Jiang, Y. Yin, Z. Cheng, S. Ge, and Q. Gu.* [[link](https://aclanthology.org/2023.acl-long.782.pdf)]

8. **Automatic assessment of english cefr levels using bert embeddings**, CLIC (2021)

   *V. J. Schmalz and A. Brutti.* [[linking](https://cris.fbk.eu/handle/11582/329866)]

9. **Conundrums in cross-prompt automated essay scoring: Making sense of the state of the art**, ACL (2024)

   *S. Li and V. Ng.* [[pdf](https://aclanthology.org/2024.acl-long.414.pdf)]

10. **ICLE++: Modeling ffne-grained traits for holistic essay scoring**, NAACL (2024)

    *S. Li and V. Ng.* [[pdf](https://aclanthology.org/2024.naacl-long.468.pdf)]

11. **Many hands make light work: Using essay traits to automatically score essays**, NAACL (2022)

    *R. Kumar, S. Mathias, S. Saha, and P. Bhattacharyya.* [[pdf](https://aclanthology.org/2022.naacl-main.106.pdf)]

12. **Neural automated essay scoring incorporating handcrafted features**, CCL (2020)

    *Uto, M., Xie, Y., Ueno, M.* [[pdf](https://aclanthology.org/2020.coling-main.535.pdf)]

13. **A prompt-independent and interpretable automated essay scoring method for Chinese second language writing**, CCL (2021)

    *Yupei, W., Renfen, H.* [[pdf](https://aclanthology.org/2021.ccl-1.107v2.pdf)]

14. **Automatic essay evaluation technologies in chinese writing—a systematic literature review**, Applied Sciences (2023)

    *H. Yang, Y. He, X. Bu, H. Xu, and W. Guo.* [[linking](https://www.mdpi.com/2076-3417/13/19/10737)]

15. **Improving automated essay scoring by prompt prediction and matching**, Entropy (2022)

    *Yupei, W., Renfen, H.* [[linking](https://www.mdpi.com/1099-4300/24/9/1206)]

16. **A new dataset and method for automatically grading ESOL texts**, ACL (2011)

    *Yannakoudakis, H., Briscoe, T., Medlock, B.* [[pdf](https://aclanthology.org/P11-1019.pdf)]

17. **Enhancing automated essay scoring performance via fine-tuning pre-trained language models with combination of regression and ranking**, EMNLP (2020)

    *Yang, R., Cao, J., Wen, Z., Wu, Y., He, X.* [[pdf](https://aclanthology.org/2020.findings-emnlp.141.pdf)]

18. **Task-independent features for automated essay grading**, BEA (2015)

    *Zesch, T., Wojatzki, M., Scholten-Akoun, D.* [[pdf](https://aclanthology.org/W15-0626.pdf)]

19. **Flexible domain adaptation for automated essay scoring using correlated linear regression**, EMNLP (2015)

    *Phandi, P., Chai, K.M.A., Ng, H.T.* [[pdf](https://aclanthology.org/D15-1049.pdf)]

20. **Off-topic essay detection using short prompt texts**, HLT-NAACL (2010)

    *Louis, A., Higgins, D.* [[pdf](https://aclanthology.org/W10-1013.pdf)]

21. **Automated essay scoring by maximizing human-machine agreement**, EMNLP (2013)

    *Chen, H., He, B.* [[pdf](https://aclanthology.org/D13-1180.pdf)]

22. **Neural automated essay scoring considering logical structure**, AIED (2023)

    *Yamaura, M., Fukuda, I., Uto, M.* [[link](https://link.springer.com/chapter/10.1007/978-3-031-36272-9_22)]

23. **Feature enhanced capsule networks for robust automatic essay scoring**, Machine Learning and Knowledge Discovery in Databases. (2021)

    *Sharma, A., Kabra, A., Kapoor, R.* [[pdf](https://2021.ecmlpkdd.org/wp-content/uploads/2021/07/sub_796.pdf)]

24. **On the effectiveness of curriculum learning in educational text scoring**, AAAI (2023)

    *Zeng, Z., Gasevic, D., Chen, G.* [[link](https://ojs.aaai.org/index.php/AAAI/article/view/26707)]



#### Automated Code Scoring

1. **Overcode: Visualizing variation in student solutions to programming problems at scale**, TOCHI 22(2) (2015)

   *Glassman, E.L., Scott, J., Singh, R., Guo, P.J., Miller, R.C.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/2699751)]

2. **Re-use of programming patterns or problem solving? representation of scratch programs by tgraphs to support static code analysis**, WiPSCE (2020)

   *Talbot, M., Geldreich, K., Sommer, J., Hubwieser, P.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3421590.3421604)]

3. **Codemaster–automatic assessment and grading of app inventor and snap! programs**, NFEDU 17(1) (2018)

​     *Von Wangenheim, C.G., Hauck, J.C., Demetrio, M.F., Pelle, R., Cruz Alves, N., Barbosa, H.,            	Azevedo,  L.F.* [[pdf](https://files.eric.ed.gov/fulltext/EJ1177148.pdf)]

11. **Petcha: a programming exercises teaching assistant**, TiCSE (2012)

    *Queir ́os, R.A.P., Leal, J.P.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/2325296.2325344)]

12. **Automatic grading of student code with similarity measurement**, ECML PKDD (2023)

    *Wang, D., Zhang, E., Lu, X.* [[pdf](https://2022.ecmlpkdd.org/wp-content/uploads/2022/09/sub_828.pdf)]

13. **Suggesting accurate method and class names**, FSE (2015)

    *Allamanis, M., Barr, E.T., Bird, C., Sutton, C.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/2786805.2786849?casa_token=DDUbzIH64jAAAAAA:imOQzSbbTmUX6cleJsN0i4hExeZXZCIO4HUH9lwQIjy7zd57t84eUATRiyrwho_Ku6fwH2JsMKkWqg)]

14. **A novel neural source code representation based on abstract syntax tree**, CSE (2019)

    *Zhang, J., Wang, X., Zhang, H., Sun, H., Wang, K., Liu, X.* [[link](https://ieeexplore.ieee.org/document/8812062)]

15. **code2vec: Learning distributed representations of code**, PACMPL (2019)

    *Alon, U., Zilberstein, M., Levy, O., Yahav, E.* [[pdf](https://arxiv.org/pdf/1803.09473.pdf)]

16. **Global relational models of source code**, CLR (2019)

    *Hellendoorn, V.J., Sutton, C., Singh, R., Maniatis, P., Bieber, D.* [[pdf](https://openreview.net/attachment?id=B1lnbRNtwr&name=original_pdf)]

17. **Codebert: A pre-trained model for programming and natural languages**, arXiv preprint arXiv:2002.08155 (2020)

    *Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.* [[pdf](https://arxiv.org/pdf/2002.08155.pdf)]

18. **Learning and evaluating contextual embedding of source code**, CML (2020)

    *Kanade, A., Maniatis, P., Balakrishnan, G., Shi, K.* [[pdf](https://arxiv.org/pdf/2001.00059.pdf)]

19. **Analyzing the quality of submissions in online programming courses**, arXiv preprint arXiv:2301.11158 (2023)

    *Tigina, M., Birillo, A., Golubev, Y., Keuning, H., Vyahhi, N., Bryksin, T.* [[pdf](https://arxiv.org/pdf/2301.11158.pdf)]

20. **Hyperstyle: A tool for assessing the code quality of solutions to programming assignments**, SIGCSE (2022)

    *Birillo, A., Vlasov, I., Burylov, A., Selishchev, V., Goncharov, A., Tikhomirova, E., Vyahhi, N., Bryksin, T.* [[pdf](https://arxiv.org/pdf/2112.02963.pdf)]

21. **Detecting code quality issues in pre-written templates of programming tasks in online courses**, arXiv preprint arXiv:2304.12376 (2023)

    *Birillo, A., Artser, E., Golubev, Y., Tigina, M., Keuning, H., Vyahhi, N., Bryksin, T.* [[pdf](https://arxiv.org/pdf/2304.12376.pdf)]

22. **Scale-driven automatic hint generation for coding style**, TS (2016)

    *Roy Choudhury, R., Yin, H., Fox, A.* [[pdf](https://acelab.berkeley.edu/wp-content/papercite-data/pdf/autostyle-its2016.pdf)]

23. **Automated critique of early programming antipat- terns**, SIGCSE, pp. 738–744 (2019)

    *Ureel II, L.C., Wallace, C.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3287324.3287463)]

24. **A tutoring system to learn code refactoring**, SIGCSE (2021)

    *Keuning, H., Heeren, B., Jeuring, J.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3408877.3432526)]

25. **Building a large annotated corpus of learner english: The nus corpus of learner english**, BEA (2013)

    *D. Dahlmeier, H. Ng, and S. Wu.* [[pdf](https://aclanthology.org/W13-1703.pdf)]



### Error Correction

#### Language Error Correction

1. **Rethinking the roles of large language models in chinese grammatical error correction**,  arXiv preprint arXiv:2402.11420 (2024)

   *Y. Li, S. Qin, H. Huang, Y. Li, L. Qin, X. Hu, W. Jiang, H.-T. Zheng, and P. S. Yu.* [[pdf](https://arxiv.org/pdf/2402.11420.pdf)]

2. **Lm-combiner: A contextual rewriting model for chinese grammatical error correction**,  arXiv preprint arXiv:2403.17413 (2024)

   *Y. Wang, B. Wang, Y. Liu, D. Wu, and W. Che.* [[pdf](https://arxiv.org/pdf/2403.17413.pdf)]

3. **Pillars of grammatical error correction: Comprehensive inspection of contemporary approaches in the era of large language models**,  arXiv preprint arXiv:2404.14914 (2024)

   *K. Omelianchuk, A. Liubonko, O. Skurzhanskyi, A. Chernodub, O. Korniienko, and I. Samokhin.* [[pdf](https://arxiv.org/pdf/2404.14914.pdf)]

4. **Grammatical error correction for code-switched sentences by learners of english**,  arXiv preprint arXiv:2404.12489 (2024)

   *K. W. H. Chan, C. Bryant, L. Nguyen, A. Caines, and Z. Yuan.* [[pdf](https://arxiv.org/pdf/2404.12489.pdf)]

5. **Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension**, arXiv preprint arXiv:1910.13461 (2019)

   *Lewis, M., Liu, Y., Goyal, N., Ghazvininejad, M., Mohamed, A., Levy, O., Stoyanov, V., Zettlemoyer, L.* [[pdf](https://arxiv.org/pdf/1910.13461.pdf)]

6. **System combination via quality estimation for grammatical error correction**,  arXiv preprint arXiv:2310.14947 (2023)

   *M. R. Qorib and H. T. Ng.* [[pdf](https://arxiv.org/pdf/2310.14947.pdf)]

7. **Frustratingly easy system combination for grammatical error correction**,  NAACL (2022)

   *M. R. Qorib, S.-H. Na, and H. T. Ng.* [[pdf](https://aclanthology.org/2022.naacl-main.143.pdf)]

8. **Cctc: a cross-sentence chinese text correction dataset for native speakers**,  COLING (2022)

   *B. Wang, X. Duan, D. Wu, W. Che, Z. Chen, and G. Hu.* [[pdf](https://aclanthology.org/2022.coling-1.294.pdf)]

9. **Spellgcn: Incorporating phonological and visual similarities into language models for chinese spelling check**,  ACL (2020)

   *X. Cheng, W. Xu, K. Chen, S. Jiang, F. Wang, T. Wang, W. Chu, and Y. Qi.* [[pdf](https://aclanthology.org/2020.acl-main.81.pdf)]

10. **Gector – grammatical error correction: Tag, not rewrite**,  BEA(2020)

    *Omelianchuk, K., Atrasevych, V., Chernodub, A., Skurzhanskyi, O.* [[pdf](https://aclanthology.org/2020.bea-1.16.pdf)]

11. **Fcgec: Fine-grained corpus for chinese grammatical error correction**, arXiv preprint arXiv:2210.12364 (2022)

    *Xu, L., Wu, J., Peng, J., Fu, J., Cai, M.* [[pdf](https://arxiv.org/pdf/2210.12364.pdf)]

12. **Language models are unsupervised multitask learners**,  OpenAI blog (2018)

    *A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever.* [[pdf](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)]

13. **The principles for building the “international corpus of learner chinese”**, Applied Linguistics (2011)

    *Baoli, Z.*

14. **Flacgec: A chinese grammatical error correction dataset with fine-grained linguistic annotation**, CIKM (2023)

    *Du, H., Zhao, Y., Tian, Q., Wang, J., Wang, L., Lan, Y., Lu, X.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3583780.3615119)]

15. **Interpretability for language learners using example-based grammatical error correction**, arXiv preprint arXiv:2203.07085 (2022)

    *Kaneko, M., Takase, S., Niwa, A., Okazaki, N.* [[pdf](https://arxiv.org/pdf/2203.07085.pdf)]

16. **Cpt: A pre-trained unbalanced transformer for both chinese language understanding and generation**, arXiv: Computation and Language (2021)

    *Y. Shao, Z. Geng, Y. Liu, J. Dai, F. Yang, L. Zhe, H. Bao, and X. Qiu.* [[pdf](https://arxiv.org/pdf/2109.05729)]

17. **A simple recipe for multilingual grammatical error correction**,  (2021)

    *Rothe, S., Mallinson, J., Malmi, E., Krause, S., Severyn, A.* [[pdf](https://arxiv.org/pdf/2106.03830.pdf)]

18. **Unsupervised grammatical error correction rivaling supervised methods**, EMNLP (2023)

    *H. Cao, L. Yuan, Y. Zhang, and H. T. Ng.* [[pdf](https://aclanthology.org/2023.emnlp-main.185.pdf)]

19. **Czech grammar error correction with a large and diverse corpus**, TACL (2022)

    *N ́aplava, J., Straka, M., Strakov ́a, J., Rosen, A.* [[pdf](https://aclanthology.org/2022.tacl-1.26.pdf)]

20. **Synthetic data generation for lowresource grammatical error correction with tagged corruption models**,  BEA (2024)

    *F. Stahlberg and S. Kumar.* [[pdf](https://aclanthology.org/2024.bea-1.2.pdf)]

21. **Data strategies for lowresource grammatical error correction**,  BEA (2021)

    *S. Flachs, F. Stahlberg, and S. Kumar.* [[pdf](https://aclanthology.org/2021.bea-1.12.pdf)]

22. **Grammatical error correction through round-trip machine translation**,  EACL (2023)

    *Y. Kementchedjhieva and A. Søgaard.* [[pdf](https://aclanthology.org/2023.findings-eacl.165.pdf)]

23. **Rogpt2: Romanian gpt2 for text generation**,  ICTAI (2022)

    *M. A. Niculescu, S. Ruseti, and M. Dascalu.* [[linking](https://ieeexplore.ieee.org/document/9643330)]

24. **Context-aware adversarial graph-based learning for multilingual grammatical error correction**,  ACM Transactions on Asian and Low-Resource Language Information Processing (2024)

    *N. Kumar, P. Kumar, S. Tripathy, N. Samal, D. Gountia, P. Gatla, and T. Singh.* [[linking](https://dl.acm.org/doi/10.1145/3696106)]

25. **A uniffed strategy for multilingual grammatical error correction with pre-trained cross-lingual language model**,  arXiv preprint arXiv:2201.10707 (2022)

    *X. Sun, T. Ge, S. Ma, J. Li, F. Wei, and H. Wang.* [[pdf](https://arxiv.org/pdf/2201.10707.pdf)]

26. **The conll-2014 shared task on grammatical error correction**, CoNLL (2014)

    *Ng, H.T., Wu, S.M., Briscoe, T., Hadiwinoto, C., Susanto, R.H., Bryant, C.* [[pdf](https://aclanthology.org/W14-1701.pdf)]

27. **The bea-2019 shared task on grammatical error correction**, BEA (2019)

    *Bryant, C., Felice, M., Andersen, Ø.E., Briscoe, T.* [[pdf](https://aclanthology.org/W19-4406.pdf)]

28. **Introduction to sighan 2015 bake-off for chinese spelling check**, SIGHAN (2015)

    *Tseng, Y.-H., Lee, L.-H., Chang, L.-P., Chen, H.-H.* [[pdf](https://aclanthology.org/W15-3106.pdf)]

29. **Grammar error correction in morphologically rich languages: The case of russian**, TACL (2019)

    *Rozovskaya, A., Roth, D.* [[pdf](https://aclanthology.org/Q19-1001.pdf)]

30. **The wiked error corpus: A corpus of corrective wikipedia edits and its application to grammatical error correction**, LNCS (2014)

    *Grundkiewicz, R., Junczys-Dowmunt, M.* [[pdf](https://emjotde.github.io/publications/pdf/mjd.poltal2014.draft.pdf)]

31. **Developing nlp tools with a new corpus of learner spanish**, LRE (2020)

    *Davidson, S., Yamada, A., Mira, P., Carando, A., S ́anchez-Guti ́errez, C., Sagae, K.* [[pdf](https://aclanthology.org/2020.lrec-1.894.pdf)]

32. **Ua-gec: Grammatical error correction and fluency corpus for the ukrainian language**, arxiv (2021)

    *Syvokon, O., Nahorna, O.* [[pdf](https://arxiv.org/pdf/2103.16997.pdf)]

33. **Neural grammatical error correction for romanian**, CTAI (2020)

    *Cotet, T.-M., Ruseti, S., Dascalu, M.* [[link](https://ieeexplore.ieee.org/document/9288338)]

34. **Automated postediting of documents**, arXiv: Computation and Language (1994)

    *Knight, K., Chander, I.* [[pdf](https://cdn.aaai.org/AAAI/1994/AAAI94-119.pdf)]

35. **The illinois-columbia system in the conll-2014 shared task**, CoNLL (2014)

    *Rozovskaya, A., Chang, K.-W., Sammons, M., Roth, D., Habash, N.* [[pdf](https://aclanthology.org/W14-1704.pdf)]

36. **Sequence to sequence learning with neural networks**, arXiv: Computation and Language,arXiv: Computation and Language (2014)

    *Sutskever, I., Vinyals, O., Le, Q.* [[pdf](https://arxiv.org/pdf/1409.3215.pdf)]

37. **Exploring the limits of transfer learning with a unified text-to-text transformer**, JMLR 21(1) (2020)

    *Raffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., Liu, P.J.* [[pdf](https://arxiv.org/pdf/1910.10683.pdf)]

38. **Syngec: Syntax-enhanced grammatical error correction with a tailored gec-oriented parser**, arXiv preprint arXiv:2210.12484 (2022)

    *Zhang, Y., Zhang, B., Li, Z., Bao, Z., Li, C., Zhang, M.* [[pdf](https://arxiv.org/pdf/2210.12484.pdf)]

39. **Csyngec: Incorporating constituent-based syntax for gram- matical error correction with a tailored gec-oriented parser**, arXiv preprint arXiv:2211.08158 (2022)

    *Zhang, Y., Li, Z.* [[pdf](https://arxiv.org/pdf/2211.08158.pdf)]

40. **Seq2Edits: Sequence transduction using span-level edit operations**, EMNLP (2020)

    *Stahlberg, F., Kumar, S.* [[pdf](https://aclanthology.org/2020.emnlp-main.418.pdf)]

41. **Parallel iterative edit models for local sequence transduction**,  (2019)

    *Awasthi, A., Sarawagi, S., Goyal, R., Ghosh, S., Piratla, V.* [[pdf](https://aclanthology.org/D19-1435.pdf)]

42. **EditNTS: An neu- ral programmer-interpreter model for sentence simplification through explicit editing**,  (2019)

    *Dong, Y., Li, Z., Rezagholizadeh, M., Cheung, J.C.K.* [[pdf](https://arxiv.org/pdf/1906.08104.pdf)]

43. **Encode, tag, realize: High-precision text editing**, arXiv preprint arXiv:1909.01187 (2019)

    *Malmi, E., Krause, S., Rothe, S., Mirylenka, D., Severyn, A.* [[pdf](https://arxiv.org/pdf/1909.01187.pdf)]

44. **TemplateGEC: Improving grammatical error correction with detection template**, Rogers, A., Boyd-Graber, J., Okazaki, N. (eds.) Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2023)

    *Li, Y., Liu, X., Wang, S., Gong, P., Wong, D.F., Gao, Y., Huang, H., Zhang, M.* [[pdf](https://aclanthology.org/2023.acl-long.380.pdf)] [[code](https://github.com/li-aolong/TemplateGEC)]

45. **Panini: a transformer-based grammatical error correction method for bangla**, Neural Comput. Appl. (20232)

    *N. Hossain, M. H. Bijoy, S. Islam, and S. Shatabda.* [[linking](https://link.springer.com/article/10.1007/s00521-023-09211-7)]

46. **Evaluation of datasets focused on grammatical error correction using the t5 model in slovak**,  RADIOELEKTRONIKA (2024)

    *M. Harahus, Z. Sokolova´, M. Pleva, J. Juha´r, D. Hla´dek, J. Stasˇ, and M. Koctu´rova.* [[linking](https://ieeexplore.ieee.org/document/10524071)]

47. **Gecturk web: An explainable online platform for turkish grammatical error detection and correction**,   (2024)

    *A. Gebes¸c¸e and G. G. S¸ahin.* [[pdf](https://arxiv.org/pdf/2410.12350)]

48. **Grammatical error correction for low-resource languages: The case of zarma**,  arXiv preprint arXiv:2410.15539 (2022)

    *M. K. Keita, C. Homan, S. A. Hamani, A. Bremang, M. Zampieri, H. A. Alfari, E. A. Ibrahim, and D. Owusu.* [[pdf](https://arxiv.org/pdf/2410.15539.pdf)]



#### Code Error Correction

1. **Graphcodebert: Pre-training code representations with data flow**, arXiv preprint arXiv:2009.08366 (2020)

   *Guo, D., Ren, S., Lu, S., Feng, Z., Tang, D., Liu, S., Zhou, L., Duan, N., Svyatkovskiy, A., Shengyu, F., Tufano, M., Deng, S., Clement, C., Drain, D., Sundaresan, N., Yin, J., Jiang, D., Zhou, M.* [[pdf](https://arxiv.org/pdf/2009.08366.pdf)]

2. **Unixcoder: Unified cross-modal pre-training for code representation**, arXiv preprint arXiv:2203.03850

   *Guo, D., Lu, S., Duan, N., Wang, Y., Zhou, M., Yin, J.*[[pdf](https://arxiv.org/pdf/2203.03850.pdf)]

3. **Unified pre-training for program understanding and generation**, NAACL (2021)

   *Ahmad, W., Chakraborty, S., Ray, B., Chang, K.-W.* [[pdf](https://arxiv.org/pdf/2103.06333.pdf)]

4. **CodeT5: Identifier-aware unified pre-trained encoder-decoder models for code understanding and generation**, Moens, M.-F., Huang, X., Specia, L., Yih, S.W.-t. (eds.) EMNLP (2021)

   *Wang, Y., Wang, W., Joty, S., Hoi, S.C.H.* [[pdf](https://arxiv.org/pdf/2109.00859.pdf)]

5. **Codepad: Sequence-based code generation with pushdown automaton**, (2022)

   *Dong, Y., Jiang, X., Liu, Y., Li, G., Jin, Z.*[[pdf](https://arxiv.org/pdf/2211.00818.pdf)]

6. **Cigar: Cost-efffcient program repair with llms**, arXiv preprint arXiv:2402.06598 (2024)

   *D. Hidve´gi, K. Etemadi, S. Bobadilla, and M. Monperrus.*[[pdf](https://arxiv.org/pdf/2402.06598.pdf)]

7. **A survey of learning-based automated program repair**, (2023)

   *Q. Zhang, C. Fang, Y. Ma, W. Sun, and Z. Chen.*[[pdf](https://arxiv.org/pdf/2301.03270)]

8. **Exploring true test overfftting in dynamic automated program repair using formal methods**, ICST (2021)

   *A. Nilizadeh, G. T. Leavens, X.-B. D. Le, C. S. Pa˘sa˘reanu, and D. R. Cok.*[[linking](https://ieeexplore.ieee.org/document/9438573)]

9. **Automated classiffcation of overfftting patches with statically extracted code features**, TSE (2022)

   *H. Ye, J. Gu, M. Martinez, T. Durieux, and M. Monperrus.*[[pdf](https://arxiv.org/pdf/1910.12057)]

10. **Thinkrepair: Self-directed automated program repair**, SIGSOFT (2024)

    *X. Yin, C. Ni, S. Wang, Z. Li, L. Zeng, and X. Yang.*[[pdf](https://arxiv.org/pdf/2407.20898)]

11. **Template-based neural program repair**, ICSE (2023)

    *X. Meng, X. Wang, H. Zhang, H. Sun, X. Liu, and C. Hu.*[[linking](https://ieeexplore.ieee.org/document/10172686)]

12. **Knod: Domain knowledge distilled tree decoder for automated program repair**, ICSE (2023)

    *N. Jiang, T. Lutellier, Y. Lou, L. Tan, D. Goldwasser, and X. Zhang.*[[pdf](https://arxiv.org/pdf/2302.01857)]

13. **T5apr: Empowering automated program repair across languages through checkpoint ensemble**, Journal of Systems and Software (2024)

    *R. Gharibi, M. H. Sadreddini, and S. M. Fakhrahmad.*[[pdf](https://arxiv.org/pdf/2309.15742)]

14. **Automated program repair in the era of large pre-trained language models**, ICSE (2023)

    *C. S. Xia, Y. Wei, and L. Zhang.*[[pdf](https://lingming.cs.illinois.edu/publications/icse2023a.pdf)]

15. **Sosrepair: Expressive semantic search for real-world program repair**, TSE (2019)

    *A. Afzal, M. Motwani, K. T. Stolee, Y. Brun, and C. Le Goues.*[[linking](https://ieeexplore.ieee.org/document/8854217)]

16. **Evaluating large language models trained on code**, arXiv preprint arXiv:2107.03374 (2021)

    *M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P. D. O. Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman et al.*[[pdf](https://arxiv.org/pdf/2107.03374.pdf)]

17. **Flexirepair: Transparent program repair with generic patches**, arXiv preprint arXiv:2011.13280 (2020)

    *A. Koyuncu, T. F. Bissyande´, J. Klein, and Y. L. Traon.*[[pdf](https://arxiv.org/pdf/2011.13280.pdf)]

18. **Genprog: A generic method for automatic software repair**, TSE (2011)

    *C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer.*[[linking](https://ieeexplore.ieee.org/document/6035728)]

19. **Efffcient automated program repair through fault-recorded testing prioritization**, ICSME (2013)

    *Y. Qi, X. Mao, and Y. Lei.*[[linking](https://ieeexplore.ieee.org/document/6676889)]

20. **Ast-t5: structureaware pretraining for code generation and understanding**, arXiv preprint arXiv:2401.03003 (2024)

    *J. Lu, L. Yu, X. Li, L. Yang, and C. Zuo.*[[pdf](https://arxiv.org/pdf/2401.03003.pdf)]

21. **Llama-reviewer: Advancing code review automation with large language models through parameter-efffcient ffne-tuning**, ISSRE (2023)

    *Z. Li, S. Lu, D. Guo, N. Duan, S. Jannu, G. Jenks, D. Majumder, J. Green, A. Svyatkovskiy, S. Fu, and N. Sundaresan.*[[pdf](https://arxiv.org/pdf/2308.11148)]

22. **Automating code review activities by large-scale pre-training**, ESEC/FSE (2022)

    *D. Hidve´gi, K. Etemadi, S. Bobadilla, and M. Monperrus.*[[pdf](https://arxiv.org/pdf/2203.09095)]

23. **Exploring the potential of chatgpt in automated code reffnement: An empirical study**, (2023)

    *Q. Guo, J. Cao, X. Xie, S. Liu, X. Li, B. Chen, and X. Peng.*[[pdf](https://arxiv.org/pdf/2309.08221)]

24. **Errorclr: Semantic error classiffcation, localization and repair for introductory programming assignments**, SIGIR (2023)

    *S. Han, Y. Wang, and X. Lu.* [[linking](https://dl.acm.org/doi/10.1145/3539618.3591680)]

25. **Pass-tuning: Towards structure-aware parameter-efffcient tuning for code representation learning**, EMNLP (2023)

    *N. Chen, Q. Sun, J. Wang, X. Li, and M. Gao.* [[pdf](https://aclanthology.org/2023.findings-emnlp.0.pdf)]

26. **Defects4j: a database of existing faults to enable controlled testing studies for java programs**, SSTA (2014)

    *Just, R., Jalali, D., Ernst, M.D.* [[pdf](https://homes.cs.washington.edu/~rjust/publ/defects4j_issta_2014.pdf)]

27. **The manybugs and introclass benchmarks for automated repair of c programs**, TSE (2015)

    *Le Goues, C., Holtschulte, N., Smith, E.K., Brun, Y., Devanbu, P., Forrest, S., Weimer, W.* [[link](https://ieeexplore.ieee.org/document/7153570)]

28. **Quixbugs: a multi-lingual program repair benchmark set based on the quixey challenge**, SPLASH Companion (2017)

    *Lin, D., Koppel, J., Chen, A., Solar-Lezama, A.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3135932.3135941)]

29. **Practical program repair in the era of large pre- trained language models**, arXiv preprint arXiv:2210.14179 (2022)

    *Xia, C., Wei, Y., Zhang, L.* [[pdf](https://arxiv.org/pdf/2210.14179.pdf)]

30. **An empirical study on learning bug-fixing patches in the wild via neural machine translation**, TOSEM (2018)

    *Tufano, M., Watson, C., Bavota, G., Penta, M., White, M., Poshyvanyk, D.* [[pdf](https://arxiv.org/pdf/1812.08693.pdf)]

31. **Fine-grained and accurate source code differencing**, ASE (2014)

    *Falleri, J.-R., Morandat, F., Blanc, X., Martinez, M., Monperrus, M.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/2642937.2642982?casa_token=QReCeqiMbxsAAAAA:f784W8t_mZ4aETrnjGEWgDd9sRUzK-Hw1f0hP2rwTQkkkH8BwDrU9WoHRB734tC3yhJG9BSKqF_-Pg)]

32. **Codebert: A pre-trained model for programming and natural languages**, EMNLP (2020)

    *Feng, Z., Guo, D., Tang, D., Duan, N., Feng, X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., Zhou, M.* [[pdf](https://arxiv.org/pdf/2002.08155.pdf)]

33. **A comprehensive survey of ai-driven advancements and techniques in automated program repair and code generation**,  (2024)

    *A. Anand, A. Gupta, N. Yadav, and S. Bajaj.* [[pdf](https://arxiv.org/pdf/2411.07586)]



### Demo

1. **Primeqa: The prime repository for state-of-the-art multilingualquestion answering research and development**, arXiv preprint arXiv:2301.09715 (2023)

   *Sil, A., Sen, J., Iyer, B., Franz, M., Fadnis, K., Bornea, M., Rosenthal, S., McCarley, S., Zhang, R., Kumar, V., et al.* [[pdf](https://arxiv.org/pdf/2301.09715.pdf)]

2. **TableQAKit: A Comprehensive and Practical Toolkit for Table-based Question Answering**, arXiv preprint arXiv:2310.15075 (2023)

   *F. Lei, T. Luo, P. Yang, W. Liu, H. Liu, J. Lei, Y. Huang, Y. Wei, S. He, J. Zhao et al.* [[pdf](https://arxiv.org/pdf/2310.15075.pdf)]

3. **Piggyback: Pretrained visual question answering environment for backing up non-deep learning professionals**, WSDM (2023)

   *Z. Zhang, S. Luo, J. Chen, S. Lai, S. Long, H. Chung, and S. C. Han.* [[pdf](https://arxiv.org/pdf/2211.15940)]

4. **Inside ascent: Exploring a deep commonsense knowledge base and its usage in question answering**, arXiv preprint arXiv:2105.13662 (2021)

   *T.-P. Nguyen, S. Razniewski, and G. Weikum.* [[pdf](https://arxiv.org/pdf/2105.13662.pdf)]

5. **Ukpsquare: An online platform for question answering research**, arXiv preprint arXiv:2203.13693 (2022)

   *T. Baumga¨rtner, K. Wang, R. Sachdeva, M. Eichler, G. Geigle, C. Poth, H. Sterz, H. Puerto, L. F. Ribeiro, J. Pfeiffer et al.* [[pdf](https://arxiv.org/pdf/2203.13693.pdf)]

6. **Localrqa: From generating data to locally training, testing, and deploying retrieval-augmented qa systems**, arXiv preprint arXiv:2403.00982 (2024)

   *X. Yu, Y. Lu, and Z. Yu.* [[pdf](https://arxiv.org/pdf/2403.00982.pdf)]

7. **Mwptoolkit: an open-source framework for deep learning-based math word problem solvers**, AAAI, vol. 36 (2022)

   *Lan, Y., Wang, L., Zhang, Q., Lan, Y., Dai, B.T., Wang, Y., Zhang, D., Lim, E.- P.* [[link](https://ojs.aaai.org/index.php/AAAI/article/view/21723)]

8. **Mwpranker: An expression similarity based math word problem retriever**, ECML-PKDD (2023)

   *M. Goel, V. Venktesh, and V. Goyal.* [[pdf](https://arxiv.org/pdf/2307.01240)]

9. **A practical toolkit for multilingual question and answer generation**, arXiv preprint arXiv:2305.17416 (2023)

   *Ushio, A., Alva-Manchego, F., Camacho-Collados, J.* [[pdf](https://arxiv.org/pdf/2305.17416.pdf)]

10. **An automatic question usability evaluation toolkit**,  (2024)

    *S. Moore, E. Costello, H. A. Nguyen, and J. Stamper.* [[pdf](https://arxiv.org/pdf/2405.20529)]

11. **Answerquest: A system for generating question-answer items from multi-paragraph documents**, arXiv preprint arXiv:2103.03820 (2021)

    *M. Roemmele, D. Sidhpura, S. DeNeefe, and L. Tsou.* [[pdf](https://arxiv.org/pdf/2103.03820.pdf)]

12. **Leaf: Multiple-choice question generation**, ECIR (2022)

    *K. Vachev, M. Hardalov, G. Karadzhov, G. Georgiev, I. Koychev, and P. Nakov.* [[pdf](https://arxiv.org/pdf/2201.09012)]

13. **Lingglewrite: a coaching system for essay writing**, ACL (2020)

    *Tsai, C.-T., Chen, J.-J., Yang, C.-Y., Chang, J.S.* [[pdf](https://aclanthology.org/2020.acl-demos.17.pdf)]

14. **Expats: a toolkit for explainable automated text scoring**, arXiv preprint arXiv:2104.03364 (2021)

    *H. Manabe and M. Hagiwara.* [[pdf](https://arxiv.org/pdf/2104.03364.pdf)]

15. **Automatic annotation and evaluation of error types for grammatical error correction.**, ACL (2017)

    *C. Bryant, M. Felice, and E. Briscoe.* [[pdf](https://aclanthology.org/P17-1074.pdf)]

16. **Wamp: Writing, annotation, and marking platform**, IJCNLP (2023)

    *QG. Moon, M. R. Qorib, D. Dahlmeier, and H. T. Ng.* [[pdf](https://aclanthology.org/2023.ijcnlp-demo.8.pdf)]

17. **Gecko+: a grammatical and discourse error correction tool**, ATALA (2021)

    *E. Calo`, L. Jacqmin, T. Rosemplatt, M. Amblard, M. Couceiro, and A. Kulkarni.* [[pdf](https://aclanthology.org/2021.jeptalnrecital-demo.3.pdf)]

18. **Efffdit: An assistant for improving writing efffciency**, ACL (2023)

    *S. Shi, E. Zhao, W. Bi, D. Cai, L. Cui, X. Huang, H. Jiang, D. Tang, K. Song, L. Wang et al.* [[pdf](https://aclanthology.org/2023.acl-demo.49.pdf)]

19. **Codegeex: A pre-trained model for code generation with multilingual evaluations on humaneval-x**, arXiv preprint arXiv:2303.17568 (2023)

    *Zheng, Q., Xia, X., Zou, X., Dong, Y., Wang, S., Xue, Y., Wang, Z., Shen, L., Wang, A., Li, Y., et al.* [[pdf](https://arxiv.org/pdf/2303.17568.pdf)]

20. **Patterns of student help-seeking when using a large language model-powered programming assistant**, ACE (2024)

    *B. Sheese, M. Lifffton, J. Savelka, and P. Denny.* [[pdf](https://arxiv.org/pdf/2310.16984)]

21. **Marscode agent: Ai-native automated bug ffxing**,  (2024)

    *Y. Liu, P. Gao, X. Wang, J. Liu, Y. Shi, Z. Zhang, and C. Peng.* [[pdf](https://arxiv.org/pdf/2409.00899)]



### Future Trends & Conclusion

1. **Bioact: Biomedical knowledge base construction using active learning**, bioRxiv (2022)

   *D. Wright, A. L. Gentile, N. Faux, and K. L. Beck.* [[linking](https://www.biorxiv.org/content/10.1101/2022.04.14.488416v1)]

2. **Patterns of student help-seeking when using a large language model-powered programming assistant**, ACE (2024)

   *B. Sheese, M. Lifffton, J. Savelka, and P. Denny.* [[pdf](https://arxiv.org/pdf/2310.16984)]

3. **Retuyt-inco at bea 2023 shared task: Tuning open-source llms for generating teacher responses**, BEA (2023)

   *A. Baladn, I. Sastre, L. Chiruzzo, and A. Ros.* [[pdf](https://aclanthology.org/2023.bea-1.61.pdf)]

4. **Educhat: A large-scale language model-based chatbot system for intelligent education**, arXiv preprint arXiv:2308.02773 (2023)

   *Dan, Y., Lei, Z., Gu, Y., Li, Y., Yin, J., Lin, J., Ye, L., Tie, Z., Zhou, Y., Wang, Y., et al.* [[pdf](https://arxiv.org/pdf/2308.02773.pdf)]

5. **Knowledge distillation: A survey**, IJCV (2021)

   *J. Gou, B. Yu, S. J. Maybank, and D. Tao.* [[pdf](https://arxiv.org/pdf/2006.05525)]

6. **A framework for math word problem solving based on pre-training models and spatial optimization strategies**, ChineseCSCW (2022)

   *W. Fan, J. Xiao, and Y. Cao.* [[linking](https://link.springer.com/chapter/10.1007/978-981-99-2385-4_37)]

7. **From large to tiny: Distilling and reffning mathematical expertise for math word problems with weakly supervision**, ICIC (2024)

   *Q. Lin, B. Xu, Z. Huang, and R. Cai.* [[pdf](https://arxiv.org/pdf/2403.14390)]

8. **Learning to compose neural networks for question answering**, arXiv preprint arXiv:1601.01705 (2016)

   *J. Andreas, M. Rohrbach, T. Darrell, and D. Klein.* [[pdf](https://arxiv.org/pdf/1601.01705.pdf)]

9. **A survey on fairness in large language models**,  (2024)

   *Y. Li, M. Du, R. Song, X. Wang, and Y. Wang.* [[pdf](https://arxiv.org/pdf/2308.10149)]

10. **A survey on large language model (llm) security and privacy: The good, the bad, and the ugly**, High-Conffdence Computing (2024)

    *Y. Yao, J. Duan, K. Xu, Y. Cai, Z. Sun, and Y. Zhang.* [[pdf](https://arxiv.org/pdf/2312.02003)]

11. **A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions**, arXiv preprint arXiv:2311.05232 (2023)

    *L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen, W. Peng, X. Feng, B. Qin et al.* [[pdf](https://arxiv.org/pdf/2311.05232.pdf)]

12. **Privacy in large language models: Attacks, defenses and future directions**,  (2024)

    *H. Li, Y. Chen, J. Luo, J. Wang, H. Peng, Y. Kang, X. Zhang, Q. Hu, C. Chan, Z. Xu, B. Hooi, and Y. Song.* [[pdf](https://arxiv.org/pdf/2310.10383)]

13. **Challenges and opportunities of moderating usage of large language models in education**,  (2023)

    *L. Krupp, S. Steinert, M. Kiefer-Emmanouilidis, K. E. Avila, P. Lukowicz, J. Kuhn, S. Ku¨ chemann, and J. Karolus.* [[pdf](https://arxiv.org/pdf/2312.14969)]

14. **The effects of over-reliance on ai dialogue systems on students’ cognitive abilities: a systematic review**, Smart Learning Environments (2024)

    *C. Zhai, S. Wibowo, and L. D. Li.* [[linking](https://slejournal.springeropen.com/articles/10.1186/s40561-024-00316-7)]

15. **Deepdive: Declarative knowledge base construction**, ACM SIGMOD Record (2016)

    *C. De Sa, A. Ratner, C. Re´, J. Shin, F. Wang, S. Wu, and C. Zhang.* [[pdf](https://dl.acm.org/doi/pdf/10.1145/3060586)]

16. **Fonduer: Knowledge base construction from richly formatted data**, SIGMOD (2018)

    *S. Wu, L. Hsiao, X. Cheng, B. Hancock, T. Rekatsinas, P. Levis, and C. Re.* [[pdf](https://arxiv.org/pdf/1703.05028)]

17. **Fine-grained controllable text generation using non-residual prompting**, ACL (2022)

    *F. Carlsson, J. O¨ hman, F. Liu, S. Verlinden, J. Nivre, and M. Sahlgren.* [[pdf](https://aclanthology.org/2022.acl-long.471.pdf)]

18. **Rˆ3 prompting: Review, rephrase and resolve for chain-of-thought reasoning in large language models under noisy context**, arXiv preprint arXiv:2310.16535 (2023)

    *Q. Tian, H. Zhu, L. Wang, Y. Li, and Y. Lan.* [[pdf](https://arxiv.org/pdf/2310.16535.pdf)]

19. **Prompt-and-rerank: A method for zero-shot and few-shot arbitrary textual style transfer with small language models**, arXiv preprint arXiv:2205.11503 (2022)

    *M. Suzgun, L. Melas-Kyriazi, and D. Jurafsky.* [[pdf](https://arxiv.org/pdf/2205.11503.pdf)]

    

## Dataset 

The URL of the datasets we mentioned are listed here.

### QA

#### Textbook QA

| Dataset   | URL                                     |
| --------- | --------------------------------------- |
| TQA       | http://textbookqa.org                   |
| GeoSQA    | http://ws.nju.edu.cn/gaokao/geosqa/1.0/ |
| AI2D      | https://github.com/allenai/dqa-net      |
| ScienceQA | https://scienceqa.github.io/            |
| MedQA     | https://github.com/jind11/MedQA         |
| MedMCQA   | https://medmcqa.github.io               |
| TheoremQA | https://github.com/wenhuchen/TheoremQA  |



#### MWP

| Dataset           | URL                                                          |
| :---------------- | ------------------------------------------------------------ |
| Dolphin-18K       | http://research.microsoft.com/en-us/projects/dolphin/        |
| DRAW-1K           | https://www.microsoft.com/en-us/research/publication/annotating-derivations-a-new-evaluation-strategy-and-dataset-for-algebra-word-problems/ |
| Math23K           | https://ai.tencent.com/ailab/nlp/dialogue/#datasets          |
| MathQA            | https://math-qa.github.io/math-QA/                           |
| ASDiv             | https://github.com/chaochun/nlu-asdiv-dataset                |
| GSM8K             | https://github.com/openai/grade-school-math                  |
| IconQA            | https://iconqa.github.io/                                    |
| T<sub>AB</sub>MWP | https://promptpg.github.io/                                  |



### QC

| Dataset   | URL                                             |
| --------- | ----------------------------------------------- |
| SciQ      | https://allenai.org/data/sciq                   |
| RACE      | https://www.cs.cmu.edu/~glai1/data/race/        |
| LearningQ | https://dataverse.mpi-sws.org/dataverse/icwsm18 |
| KHANQ     | https://github.com/Huanli-Gong/KhanQ            |
| EduProbe  | https://github.com/my625/PromptQG               |
| EduQG     | https://github.com/hadifar/question-generation  |
| MCQL      | https://github.com/harrylclc/LTR-DG             |
| Televic   | https://github.com/semerekiros/dist-retrieval   |



### AA

#### AES

| Dataset | URL                                                          |
| ------- | ------------------------------------------------------------ |
| CLC-FCE | http://www.ilexir.com/                                       |
| ASAP    | https://www.kaggle.com/c/asap-aes                            |
| ICLE++  | https://github.com/samlee946/ICLE-PlusPlus                   |
| ELLIPSE | https://www.kaggle.com/competitions/feedback-prize-english-language-learning |
| HSK     | http://yuyanziyuan.blcu.edu.cn/en/info/1043/1501.htm         |



### EC

#### LEC

| Dataset      | URL                                                  |
| ------------ | ---------------------------------------------------- |
| LANG-8       | https://sites.google.com/site/naistlang8corpora/home |
| CoNLL-2014   | https://www.comp.nus.edu.sg/~nlp/conll14st.html      |
| BEA-2019     | https://www.cl.cam.ac.uk/research/nl/bea2019st/      |
| CCTC         | https://github.com/destwang/CTCResources             |
| FCGEC        | https://github.com/xlxwalex/FCGEC                    |
| FlaCGEC      | https://github.com/hyDududu/FlaCGEC                  |
| Falko-MERLIN | https://github.com/adrianeboyd/boyd-wnut2018         |
| COWS-L2H     | https://github.com/ucdaviscl/cowsl2h                 |
| RONACC       | https://github.com/TeodorMihai/RoGEC                 |



#### CEC

| Dataset        | URL                                                          |
| -------------- | ------------------------------------------------------------ |
| Defects4J      | https://github.com/rjust/defects4j                           |
| ManyBugs       | https://repairbenchmarks.cs.umass.edu/                       |
| IntroClass     | https://repairbenchmarks.cs.umass.edu/                       |
| QuixBugs       | https://github.com/jkoppel/QuixBugs                          |
| Bugs2Fix       | https://sites.google.com/view/learning-fixes                 |
| CodeReview     | https://github.com/microsoft/CodeBERT/tree/master/CodeReviewer |
| CodeReview-New | https://sites.google.com/view/chatgptcodereview              |



## Citation

```
@article{lan2024survey,
  title={Survey of Natural Language Processing for Education: Taxonomy, Systematic Review, and Future Trends},
  author={Lan, Yunshi and Li, Xinyuan and Du, Hanyue and Lu, Xuesong and Gao, Ming and Qian, Weining and Zhou, Aoying},
  journal={arXiv preprint arXiv:2401.07518},
  year={2024}
}
```

